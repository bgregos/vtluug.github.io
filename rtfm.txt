This document describes how to build the infrastructure from scratch, as well manage it in general. 

'SCRIPTS' refers to the scripts repo, found at https://github.com/vtluug/scripts
'ANSIBLE' refers to the ansible repo, found at https://github.com/vtluug/ansible

For ansible:
- Install it
- Install any additional packages in the ansible readmeg


Table of Contents
0. Summary
1. Installation
2. Networking
3. Configuration

Summary
======
NFS Configuration:
- Proxmox VM storage:
    - Handles all the details; we only provide export path, storage type, and storage id
    - images    cistern-images    10.98.0.7:/cistern/nfs/pve/images
    - isos      cistern-isos      10.98.0.7:/cistern/nfs/pve/isos
    - backup    tank-backup       10.98.0.6:/tank/nfs/pve/backup
    - backup    keg-backup        10.98.0.8:/keg/nfs/pve/backup
- All hosts:
    - 755 root:root         /nfs
    - 755 root:root         /nfs/tank
    - 775 nobody:users      /nfs/tank/share     10.98.0.6:/tank/nfs/share
    - 777 root:root         /nfs/tank/scratch   10.98.0.6:/tank/nfs/scratch
    - 755 root:root         /nfs/cistern
    - 775 nobody:users      /nfs/cistern/share  10.98.0.7:/cistern/nfs/share
    - 755 root:root         /nfs/keg
    - 775 nobody:users      /nfs/keg/share      10.98.0.8:/keg/nfs/share
    - 777 root:root         /nfs/keg/scratch    10.98.0.8:/keg/nfs/scratch
- All hosts EXCEPT Proxmox:
    - 755 root:root         /home               10.98.0.7:/cistern/nfs/home
    - 755 www-data:www-data /nfs/cistern/files  10.98.0.7:/cistern/nfs/files
- Sczi:
    - 755 root:root /nfs/cistern/srv 10.98.0.7:/cistern/nfs/srv



Installation (Baremetal)
========================

Proxmox Hosts
- Use vtluug+notifications@gmail.com for the email address requested at installation

Non-Proxmox Hosts
- Create the papatux user with the password in the vtluug-admin repo
    - This is used as a general admin account

If any hosts are installed without internet connection, make sure you install & enable ssh, and install python once internet works.

More configuration will be done in the 'Configuration' section after Networking



Networking
==========
- IPs and MACs of hosts are listed in scripts/router/lan/local_hosts
- Hosts get IPv4 address assigned using DHCP based on MAC, and IPv6 are assigned using SLAAC
- Set up physical boxes based on architecture_pic.png TODO


Switch
------
- Ensure IGMP multicast querying & snooping are enabled. Test it here: https://pve.proxmox.com/wiki/Multicast_notes#Using_omping_to_test_multicast
    - This is required for the Proxmox cluster


Router (Debian)
---------------

Configure IP addresses
- Copy SCRIPTS/router/ip-config/interfaces into /etc/network/interfaces

Configure ARP Proxying
- Copy SCRIPTS/router/proxy/arp_proxy.sh into /usr/local/bin/
- Copy SCRIPTS/router/proxy/arp_proxy.service into /etc/systemd/system
- Start and enable arp_proxy.service

Configure dnsmasq (DHCP/SLAAC/DNS) & resolv.conf
- Install dnsmasq
- Copy SCRIPTS/router/lan/dnsmasq.conf into /etc/dnsmasq.conf
- Copy SCRIPTS/router/lan/local_hosts into /usr/local/bin
- Copy SCRIPTS/router/lan/resolv.conf into /etc/resolv.conf
- Start and enable dnsmasq.service

Configure iptables (NAT/Firewall)
- Install iptables
- Copy SCRIPTS/router/lan/vtluug_iptables.sh into /usr/local/bin
- Copy SCRIPTS/router/lan/vtluug_iptables.service into /etc/systemd/system
- Start and enable vtluug_iptables.service



Configuration
=============
These steps MUST be done in order. YMMV otherwise.

Proxmox Hosts
- Create the papatux user with sudo privileges, *not* using the same username as your ldap username
- Create the cluster following this guide: https://pve.proxmox.com/wiki/Cluster_Manager
- If you use firefox and a touchscreen you must disable 'dom.w3c_touch_events.enabled' in about:config for the Proxmox web GUI to work on your device
    - Yeah, it's stupid; get over it

Ensure python is installed on all bare metal hosts
**At this point, all bare metal hosts should have an admin user created, so root ssh will be disabled in the following step

NFS
To build each zfs pool, first look up the device ids in /dev/disk/by-id since these are guaranteed to not change (unlike /dev/sdX)
- Install 'zfsutils-linux' firs to install the zfs utils
- Cyberdelia - 7 1TB drives in a raidz3 zfs pool named 'tank'
    - Similarly, run 'zpool create -f -o ashift=12 keg raidz2 <disk_1_id> <disk_2_id> ... <disk_7_id>
- Dirtycow - 8 2TB drives in a raidz3 pool named 'cistern'
    - Similarly, run 'zpool create -f -o ashift=12 keg raidz2 <disk_1_id> <disk_2_id> ... <disk_8_id>
- Shellshock - 3 500GB drives in a raidz2 zfs pool named 'keg'
    - Run 'zpool create -f -o ashift=12 keg raidz1 <disk_1_id> <disk_2_id> <disk_3_id>
- Run 'zfs create <directory>' accoring to the 'NFS Configuration' section in the beginning of the document.
- Set the proper permissions accoring to the 'NFS Configuration' section as well.

Baremetal Hosts
- Make sure you've copied your ssh key to all the baremetal servers so ansible works
- Run 'ansible-playbook main.yml -i hosts.cfg -K -u papatux --limit=baremetal'
    - Configures most things for us


Creating the VM templates
- We need to manually install a VM first, then we'll make that into a few templates to build everything else on
- Don't worry, this is the only part involving touching the GUI :P
- Download the latest ubuntu iso to dirtycow.private.vtluug.org:/cistern/nfs/pve/isos/template/iso/
    - I recommend not using the net-installer for ubuntu if installing via VNC on proxmox
    - Go to https://10.98.0.3:8006, and log in as root
    - Creating the base template
        - Click 'Create VM' in the top right corner
        - Check the 'Advanced' checkbox in the bottom right corner
        - In the 'General' tab, put 'ubuntu-tiny' in the 'Name' field and check the 'Start at boot' checkbox
        - In the 'OS' tab, select 'dirtycow_isos' in the 'Storage' field and the latest ubuntu LTS (SERVER edition) you just downloaded in the 'ISO image' field
        - In the 'Hard Disk' tab, select 'dirtycow_images' is selected in the 'Storage' field and put '10' in the 'Disk size (GiB)' field
        - In the 'CPU' tab, select '1' in the 'Cores' field
        - In the 'Memory' tab, put '1024' in the 'Memory (MiB)' field
        - In the 'Network' tab, do nothing
        - In the 'Confirm' tab, make sure everything is correct
        - Finally, click 'Finish'
        - Once installation is finished we'll convert this into a template and make the 'ubuntu-small' and 'ubuntu-medium' templates then create the actual VMs from those
    - Installing the base template
        - In the top right corner, select 'Start'
        - From the left inner sidebar, select 'Console' to see a VNC session of the VM
        - Use the default options until you get to the 'Hostname' prompt, and use 'template' (Note: *not* {ubuntu,centos}-tiny)
        - Use 'papatux' for the name and username, and the password from the vtluug-admin repo for the password
        - Use 'Guided - use entire disk' for partitioning
        - Use the defaults then wait awhile...
        - Select 'Install security updates automatically'
        - At the 'Software Selection' screen, select 'OpenSSH server'
        - Use the defaults then wait while it finishes installing
        - Reboot into the system, install sudo if not already installed, and make sure papatux is in the sudo/wheel group (depending on distro)
        - Run 'sudo apt install python' bc ansible requires python2
        - Also run 'sudo rm /etc/machin-id' and edit /etc/crontab:
            - Add '@reboot root test -f /etc/machine-id || ( systemd-machine-id-setup && reboot )'
            - This creates unique uuids for VMs; otherwise they'd all be the same
        - Select 'Shutdown' in the top right corner
        - Still on the 'Hardware' tab, right click on 'CD/DVD Drive' and select 'Do not use any media'
        - In case you're wondering, MACs are automatically changed during a clone
    - Creating the templates
        - Here, we're taking the VM just created, converting it to a template, then cloning it to make 2 more templates
        - From the left outer sidebar, select Datacenter > meltdown > 100 (ubuntu-tiny)
        - Select More > Convert to template
        - Select More > Clone
        - Put 'ubuntu-small' in the 'Name' field
        - Select 'Full Clone' in the 'Mode' field then click 'Clone'
        - From the left outer sidebar, select Datacenter > meltdown > 101 (ubuntu-small)
        - Select 'Hardware' in the left inner sidebar
        - Double click 'Memory' and change it to '2048'
        - Double click 'Processors' and change it to '2'
        - Cilck More > Convert to template from the top right corner
        - Repeat these steps, except name the template 'ubuntu-medium', use 4 cores, and 4096 Memory
    - Repeat the above steps using the latest Centos MINIMAL image, except only create the 'centos-tiny' template
        - Note: Don't forget to set the hostname to 'template' during installation since it's less obvious
        - This will (only) be used for the freeipa server, because fuck freeipa
    - Finally, you should have a tiny, small, and medium ubuntu template, and a centos tiny template
        - Where tiny = 1 core, 1GB ram, small = 2 core, 2GB ram, and medium = 4 core, 4GB ram


Creating the VMs
- Set the PROXMOX_PASSWORD environment variable to the root proxmox password
- Run 'ansible-playbook deploy.yml -i hosts.cfg -u papatux -k -K'
    - -K and -k are used because newly deployed vms don't have ssh keys or passwordless sudo (yet)
    - This will result in some hosts showing "unreachable" because some VMs require a reboot after initial configuration
- If some hosts are *not* successfully created, remove those (from proxmox) and try again (this shouldn't happen)

- Configuring FreeIPA Server
    - First run 'ansible-playbook main.yml -i hosts.cfg -u papatux -k K --limit=chimera.private.vtluug.org' to install all the required packages
    - Reboot chimera, since some tasks require a reboot to take effect
    - The configuration is not automated because it is only done once, and you should be aware of how it's configured
    - ssh into chimera,
    - Run 'ipa-server-install' (as root)
    - Use these options:
        - Do you want to configure integrated DNS (BIND)? [no]: yes
        - Server host name: chimera.private.vtluug.org
        - Domain name: krb.vtluug.org
        - Realm name: KRB.VTLUUG.ORG
        - Directory Manager PW: see accounts file in gitolite-admin
        - admin PW: See accounts file in gitolite-admin
        - Configure DNS forwarders: yes
        - Search for missing reverse zones: yes
        - Continue to configure system with these values: yes
    - Run 'kinit admin' to authenticate as admin
    - Create 'users' and 'officers' groups and change the default shell
        - 'ipa group-add users --desc "All VTLUUG members"'
        - 'ipa group-add officers --desc "VTLUUG officers"'
        - 'ipa config-mod --defaultgroup users'
        - 'ipa config-mod --defaultshell=/bin/bash'

Configure NFS for freeipa login
    - Since FreeIPA didn't exist when we configured NFS, you need to do a bit of config
    - Run 'ipa-client-install -U --domain=krb.vtluug.org --server=chimera.private.vtluug.org --principal=admin --password=$FREEIPA_ADMIN_PASSWORD

Configuring the new VM (And the nfs hosts for freeipa login)
- Run 'ansible-playbook main.yml -i hosts.cfg -u papatux -k -K --limit=vms'
    - This mostly configures all the new hosts
